{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/shared-dev/Development/UniProjects/CompilerConstruction/A2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "import pprint\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token(object):\n",
    "    KEYWORD, ID, SYM, STRCONST, INTCONST, READCONST, ASSIGN, COLON, COMMA, SEMICOLON, DOT, EQ, NQ, LT, LTE, GT, GTE, QUOTE, INTEGER, PLUS, MINUS, MUL, DIV, LPAREN, RPAREN, EOF, TERM, AND, OR, NOT = (\n",
    "    'KEYWORD', 'ID', 'SYM', 'STRCONST', 'INTCONST', 'READCONST', \"ASSIGN\",\n",
    "    \"COLON\", \"COMMA\", \"SEMICOLON\", \"DOT\", \"EQ\", \"NQ\", \"LT\", \"LTE\", \"GT\", \"GTE\",\"QUOTE\", 'INTEGER', 'PLUS', 'MINUS', 'MUL',\n",
    "    'DIV', '(', ')', 'EOF', 'TERM', 'AND', 'OR', 'NOT')\n",
    "\n",
    "    KEYWORDS = (\"PROGRAM\", \"VAR\", \"DIV\", \"INTEGER\", \"REAL\", \"BEGIN\", \"END\",\n",
    "            \"PROCEDURE\", \"IF\", \"THEN\", \"ELSE\", \"WHILE\", \"REPEAT\", \"UNTIL\", \"WRITE\", \"WRITELN\", \"OR\", \"AND\", \"DIV\", \"MOD\", \"NOT\", \"TRUNC\", \"REAL\", \"DO\")\n",
    "    \n",
    "    def __init__(self, type, value, line_no, col_no):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.line_no = line_no\n",
    "        self.col_no = col_no - len(str(value))\n",
    "#         self.position = pos\n",
    "        self.inverse = False\n",
    "        \n",
    "        self.row = []\n",
    "    \n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Token({type}, {value}, {line_no}, {position})'.format(type=self.type,\n",
    "                                               value=repr(self.value), line_no=self.line_no, position=self.col_no)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class Lexer(object):\n",
    "    def __init__(self, text):\n",
    "        # client string input, e.g. \"hello | world & (why | are | you)\"\n",
    "        self.text = text\n",
    "        # self.pos is an index into self.text\n",
    "        self.pos = 0\n",
    "        self.col_no = 0\n",
    "        self.current_char = self.text[self.pos]\n",
    "        self.line_no = 0\n",
    "        self.symbol_table = {}\n",
    "\n",
    "    def error(self):\n",
    "        raise Exception('Invalid character')\n",
    "\n",
    "    def peek(self):\n",
    "        if self.pos + 1 < len(self.text):\n",
    "            return self.text[self.pos + 1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def advance(self):\n",
    "        self.pos += 1\n",
    "        self.col_no += 1\n",
    "    \n",
    "        if '\\n'in [self.current_char]:\n",
    "            self.line_no += 1\n",
    "            self.col_no = 0\n",
    "            \n",
    "        if self.pos > len(self.text) - 1:\n",
    "            self.current_char = None  # Indicates end of input\n",
    "        else:\n",
    "            self.current_char = self.text[self.pos]\n",
    "\n",
    "    def skip_whitespace(self):\n",
    "        while self.current_char is not None and self.current_char.isspace():\n",
    "            self.advance()\n",
    "\n",
    "    def integer(self):\n",
    "        result = ''\n",
    "        while self.current_char is not None and self.current_char.isdigit():\n",
    "            result += self.current_char\n",
    "            self.advance()\n",
    "        return int(result)\n",
    "\n",
    "    def word(self):\n",
    "        result = ''\n",
    "        while self.current_char is not None and (self.current_char.isalpha()\n",
    "                                                 or self.current_char == '_'):\n",
    "            result += self.current_char\n",
    "            self.advance()\n",
    "        if result.upper() in Token.KEYWORDS:\n",
    "            return Token(Token.KEYWORD, str(result), self.line_no, self.col_no)\n",
    "        else:\n",
    "            self.symbol_table[str(result)] = self.pos\n",
    "            return Token(Token.ID, str(result), self.line_no, self.col_no)\n",
    "\n",
    "    def readStringConst(self):\n",
    "        result = '\"'\n",
    "        self.advance()\n",
    "        while self.current_char is not None:\n",
    "            result += self.current_char\n",
    "            if self.current_char == '\"':\n",
    "                self.advance()\n",
    "                break\n",
    "            self.advance()\n",
    "\n",
    "        return Token(Token.STRCONST, str(result), self.line_no, self.col_no)\n",
    "    \n",
    "    def update_symbol_table(self):\n",
    "        token_list = self.get_all_tokens()\n",
    "        symbol_table = {}\n",
    "        for i in range(0, len(token_list)):\n",
    "#             print(token_list[i].value)\n",
    "            if token_list[i].value == \"PROGRAM\".lower():\n",
    "                symbol_table[token_list[i+1].value] = \"PROGRAM\"\n",
    "            \n",
    "            if token_list[i].value == \":\":\n",
    "                symbol_table[token_list[i-1].value] = token_list[i+1].value\n",
    "        self.symbol_table = symbol_table\n",
    "        return symbol_table\n",
    "    \n",
    "    def get_all_tokens(self):\n",
    "        token_list = []\n",
    "        temp_pos = self.pos\n",
    "        temp_current_char = self.current_char\n",
    "        temp_line_no = self.line_no\n",
    "        self.pos = 0\n",
    "        self.current_char = self.text[self.pos]\n",
    "        self.line_no = 0\n",
    "        token = lexer.get_next_token()\n",
    "        while token.type != Token.EOF:\n",
    "            token_list.append(token)\n",
    "            token = lexer.get_next_token()\n",
    "            \n",
    "        self.pos = temp_pos\n",
    "        self.current_char = temp_current_char\n",
    "        self.line_no = temp_line_no\n",
    "        return token_list\n",
    "        \n",
    "    def get_next_token(self):\n",
    "        while self.current_char is not None:\n",
    "            if self.current_char.isspace():\n",
    "                self.skip_whitespace()\n",
    "                continue\n",
    "\n",
    "            if self.current_char.isdigit():\n",
    "                return Token(Token.INTCONST, self.integer(), self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char.isalpha():\n",
    "                #                 print('Got Identifier  ' + self.current_char)\n",
    "                return self.word()\n",
    "\n",
    "            if self.current_char == ':' and self.peek() == '=':\n",
    "                self.advance()\n",
    "                self.advance()\n",
    "                return Token(Token.ASSIGN, \":=\", self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == ':':\n",
    "                self.advance()\n",
    "                return Token(Token.COLON, \":\", self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == ',':\n",
    "                self.advance()\n",
    "                return Token(Token.COMMA, \",\", self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == ';':\n",
    "                self.advance()\n",
    "                return Token(Token.SEMICOLON, \";\", self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '.':\n",
    "                self.advance()\n",
    "                return Token(Token.DOT, \".\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '!':\n",
    "\n",
    "                self.advance()\n",
    "                return Token(Token.NOT, 'NOT', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '&':\n",
    "\n",
    "                self.advance()\n",
    "                return Token(Token.AND, 'AND', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '|':\n",
    "\n",
    "                self.advance()\n",
    "                return Token(Token.OR, 'OR', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '+':\n",
    "                self.advance()\n",
    "                return Token(Token.PLUS, '+', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '-':\n",
    "                self.advance()\n",
    "                return Token(Token.MINUS, '-', self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '\"':\n",
    "                return self.readStringConst()\n",
    "\n",
    "            if self.current_char == '*':\n",
    "                self.advance()\n",
    "                return Token(Token.MUL, '*', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '/':\n",
    "                self.advance()\n",
    "                return Token(Token.DIV, '/', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == '=':\n",
    "                self.advance()\n",
    "                return Token(Token.EQ, \"=\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '<' and self.peek() == '>':\n",
    "                self.advance()\n",
    "                self.advance()\n",
    "                return Token(Token.NEQ, \"<=\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '<':\n",
    "                self.advance()\n",
    "                return Token(Token.LT, \"<\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '<' and self.peek() == '=':\n",
    "                self.advance()\n",
    "                self.advance()\n",
    "                return Token(Token.LTE, \"<=\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '>' :\n",
    "                self.advance()\n",
    "                return Token(Token.GT, \">\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '>' and self.peek() == '=':\n",
    "                self.advance()\n",
    "                self.advance()\n",
    "                return Token(Token.GTE, \">=\", self.line_no, self.col_no)\n",
    "            \n",
    "            if self.current_char == '(':\n",
    "                self.advance()\n",
    "                return Token(Token.LPAREN, '(', self.line_no, self.col_no)\n",
    "\n",
    "            if self.current_char == ')':\n",
    "                self.advance()\n",
    "                return Token(Token.RPAREN, ')', self.line_no, self.col_no)\n",
    "            print(\"before error \",self.current_char)\n",
    "            self.error()\n",
    "\n",
    "        return Token(Token.EOF, None, self.line_no, self.col_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "lexer = Lexer(text)\n",
    "token = lexer.get_next_token()\n",
    "while token.type != Token.EOF:\n",
    "    print(token)\n",
    "    token = lexer.get_next_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open(\"./inputs/source_code.pas\", 'r') as pascal_file:\n",
    "    text = \"\".join(pascal_file.readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(KEYWORD, 'program', 0, 0)\n",
      "Token(ID, 'checkMyAbility', 0, 8)\n",
      "Token(SEMICOLON, ';', 0, 22)\n",
      "Token(KEYWORD, 'var', 1, 0)\n",
      "Token(ID, 'counter', 2, 0)\n",
      "Token(COLON, ':', 2, 7)\n",
      "Token(KEYWORD, 'integer', 2, 9)\n",
      "Token(SEMICOLON, ';', 2, 16)\n",
      "Token(ID, 'number', 3, 0)\n",
      "Token(COLON, ':', 3, 6)\n",
      "Token(KEYWORD, 'integer', 3, 8)\n",
      "Token(SEMICOLON, ';', 3, 15)\n",
      "Token(ID, 'factorial', 4, 0)\n",
      "Token(COLON, ':', 4, 9)\n",
      "Token(KEYWORD, 'integer', 4, 11)\n",
      "Token(SEMICOLON, ';', 4, 18)\n",
      "Token(ID, 'height', 5, 0)\n",
      "Token(COLON, ':', 5, 7)\n",
      "Token(KEYWORD, 'real', 5, 9)\n",
      "Token(SEMICOLON, ';', 5, 13)\n",
      "Token(ID, 'width', 6, 0)\n",
      "Token(COLON, ':', 6, 6)\n",
      "Token(KEYWORD, 'real', 6, 8)\n",
      "Token(SEMICOLON, ';', 6, 12)\n",
      "Token(ID, 'breadth', 7, 0)\n",
      "Token(COLON, ':', 7, 8)\n",
      "Token(KEYWORD, 'real', 7, 10)\n",
      "Token(SEMICOLON, ';', 7, 14)\n",
      "Token(ID, 'volume', 8, 0)\n",
      "Token(COLON, ':', 8, 7)\n",
      "Token(KEYWORD, 'real', 8, 9)\n",
      "Token(SEMICOLON, ';', 8, 13)\n",
      "Token(KEYWORD, 'begin', 9, 0)\n",
      "Token(ID, 'number', 10, 0)\n",
      "Token(ASSIGN, ':=', 10, 7)\n",
      "Token(INTCONST, 6, 10, 10)\n",
      "Token(SEMICOLON, ';', 10, 11)\n",
      "Token(ID, 'counter', 11, 0)\n",
      "Token(ASSIGN, ':=', 11, 8)\n",
      "Token(ID, 'number', 11, 11)\n",
      "Token(SEMICOLON, ';', 11, 17)\n",
      "Token(ID, 'factorial', 12, 0)\n",
      "Token(ASSIGN, ':=', 12, 10)\n",
      "Token(INTCONST, 1, 12, 13)\n",
      "Token(KEYWORD, 'while', 13, 0)\n",
      "Token(ID, 'counter', 13, 6)\n",
      "Token(GT, '>', 13, 14)\n",
      "Token(INTCONST, 0, 13, 16)\n",
      "Token(KEYWORD, 'do', 13, 18)\n",
      "Token(KEYWORD, 'begin', 13, 21)\n",
      "Token(ID, 'number', 14, 0)\n",
      "Token(ASSIGN, ':=', 14, 7)\n",
      "Token(ID, 'number', 14, 10)\n",
      "Token(MUL, '*', 14, 17)\n",
      "Token(ID, 'counter', 14, 19)\n",
      "Token(SEMICOLON, ';', 14, 26)\n",
      "Token(ID, 'counter', 15, 0)\n",
      "Token(ASSIGN, ':=', 15, 8)\n",
      "Token(ID, 'counter', 15, 11)\n",
      "Token(MINUS, '-', 15, 19)\n",
      "Token(INTCONST, 1, 15, 21)\n",
      "Token(SEMICOLON, ';', 15, 22)\n",
      "Token(KEYWORD, 'end', 16, 0)\n",
      "Token(SEMICOLON, ';', 16, 3)\n",
      "Token(ID, 'height', 17, 0)\n",
      "Token(ASSIGN, ':=', 17, 7)\n",
      "Token(INTCONST, 8, 17, 10)\n",
      "Token(DOT, '.', 17, 11)\n",
      "Token(INTCONST, 5, 17, 12)\n",
      "Token(SEMICOLON, ';', 17, 13)\n",
      "Token(ID, 'width', 18, 0)\n",
      "Token(ASSIGN, ':=', 18, 6)\n",
      "Token(INTCONST, 4, 18, 9)\n",
      "Token(DOT, '.', 18, 10)\n",
      "Token(INTCONST, 5, 18, 11)\n",
      "Token(SEMICOLON, ';', 18, 12)\n",
      "Token(ID, 'breadth', 19, 0)\n",
      "Token(ASSIGN, ':=', 19, 8)\n",
      "Token(INTCONST, 2, 19, 11)\n",
      "Token(DOT, '.', 19, 12)\n",
      "Token(INTCONST, 25, 19, 13)\n",
      "Token(SEMICOLON, ';', 19, 15)\n",
      "Token(ID, 'volume', 20, 0)\n",
      "Token(ASSIGN, ':=', 20, 7)\n",
      "Token(ID, 'height', 20, 10)\n",
      "Token(MUL, '*', 20, 17)\n",
      "Token(ID, 'width', 20, 19)\n",
      "Token(MUL, '*', 20, 25)\n",
      "Token(ID, 'breadth', 20, 27)\n",
      "Token(SEMICOLON, ';', 20, 34)\n",
      "Token(KEYWORD, 'if', 21, 0)\n",
      "Token(ID, 'volume', 21, 3)\n",
      "Token(GT, '>', 21, 10)\n",
      "Token(EQ, '=', 21, 11)\n",
      "Token(INTCONST, 100, 21, 13)\n",
      "Token(KEYWORD, 'and', 21, 17)\n",
      "Token(ID, 'number', 21, 21)\n",
      "Token(LT, '<', 21, 28)\n",
      "Token(INTCONST, 5, 21, 30)\n",
      "Token(KEYWORD, 'then', 21, 32)\n",
      "Token(KEYWORD, 'begin', 21, 37)\n",
      "Token(ID, 'volume', 22, 0)\n",
      "Token(ASSIGN, ':=', 22, 7)\n",
      "Token(ID, 'volume', 22, 10)\n",
      "Token(DIV, '/', 22, 17)\n",
      "Token(INTCONST, 4, 22, 19)\n",
      "Token(SEMICOLON, ';', 22, 20)\n",
      "Token(KEYWORD, 'end', 23, 0)\n",
      "Token(KEYWORD, 'else', 24, 0)\n",
      "Token(KEYWORD, 'begin', 24, 5)\n",
      "Token(KEYWORD, 'if', 25, 0)\n",
      "Token(ID, 'volume', 25, 3)\n",
      "Token(GT, '>', 25, 10)\n",
      "Token(EQ, '=', 25, 11)\n",
      "Token(INTCONST, 50, 25, 13)\n",
      "Token(KEYWORD, 'or', 25, 16)\n",
      "Token(ID, 'number', 25, 19)\n",
      "Token(LT, '<', 25, 26)\n",
      "Token(INTCONST, 10, 25, 28)\n",
      "Token(KEYWORD, 'then', 25, 31)\n",
      "Token(KEYWORD, 'begin', 25, 36)\n",
      "Token(ID, 'volume', 26, 0)\n",
      "Token(ASSIGN, ':=', 26, 7)\n",
      "Token(ID, 'volume', 26, 10)\n",
      "Token(DIV, '/', 26, 17)\n",
      "Token(INTCONST, 2, 26, 19)\n",
      "Token(SEMICOLON, ';', 26, 20)\n",
      "Token(KEYWORD, 'end', 27, 0)\n",
      "Token(KEYWORD, 'end', 28, 0)\n",
      "Token(SEMICOLON, ';', 28, 3)\n",
      "Token(KEYWORD, 'write', 29, 0)\n",
      "Token((, '(', 29, 5)\n",
      "Token(STRCONST, '\"Factorial of \"', 29, 6)\n",
      "Token(), ')', 29, 21)\n",
      "Token(SEMICOLON, ';', 29, 22)\n",
      "Token(KEYWORD, 'write', 30, 0)\n",
      "Token((, '(', 30, 5)\n",
      "Token(ID, 'number', 30, 6)\n",
      "Token(), ')', 30, 12)\n",
      "Token(SEMICOLON, ';', 30, 13)\n",
      "Token(KEYWORD, 'write', 31, 0)\n",
      "Token((, '(', 31, 5)\n",
      "Token(STRCONST, '\" is \"', 31, 6)\n",
      "Token(), ')', 31, 12)\n",
      "Token(SEMICOLON, ';', 31, 13)\n",
      "Token(KEYWORD, 'writeln', 32, 0)\n",
      "Token((, '(', 32, 7)\n",
      "Token(ID, 'factorial', 32, 8)\n",
      "Token(), ')', 32, 17)\n",
      "Token(SEMICOLON, ';', 32, 18)\n",
      "Token(KEYWORD, 'write', 33, 0)\n",
      "Token((, '(', 33, 5)\n",
      "Token(STRCONST, '\"Some odd value is: \"', 33, 6)\n",
      "Token(), ')', 33, 27)\n",
      "Token(SEMICOLON, ';', 33, 28)\n",
      "Token(KEYWORD, 'writeln', 34, 0)\n",
      "Token((, '(', 34, 7)\n",
      "Token(ID, 'volume', 34, 8)\n",
      "Token(), ')', 34, 14)\n",
      "Token(SEMICOLON, ';', 34, 15)\n",
      "Token(KEYWORD, 'end', 35, 0)\n",
      "Token(DOT, '.', 35, 3)\n"
     ]
    }
   ],
   "source": [
    "lexer = Lexer(text)\n",
    "token = lexer.get_next_token()\n",
    "\n",
    "with open(\"./outputs/pascal_tokens.csv\", 'w') as token_file:\n",
    "    while token.type != Token.EOF:\n",
    "        print(token)\n",
    "        token_file.write(f\"{token.type}, {token.value}, {token.line_no}, {token.col_no}\\n\")\n",
    "        token = lexer.get_next_token()\n",
    "        \n",
    "with open(\"./outputs/symbol_table.csv\", 'w') as symbol_table_file:\n",
    "    for identifer, id_type in lexer.update_symbol_table().items():\n",
    "        symbol_table_file.write(f\"{identifer}, {id_type}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkMyAbility': 'PROGRAM',\n",
       " 'counter': 'integer',\n",
       " 'number': 'integer',\n",
       " 'factorial': 'integer',\n",
       " 'height': 'real',\n",
       " 'width': 'real',\n",
       " 'breadth': 'real',\n",
       " 'volume': 'real'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexer.symbol_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
